{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f05bb308160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    if (reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        # intialize weights and biases \n",
    "\n",
    "    # First convolutional and pool layers\n",
    "    # This finds 32 different 5 x 5 pixel features\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    # 32 filters with (5*5*1)\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    #Padding and strides \n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    # activation function ReLu \n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Second convolutional and pool layers\n",
    "    # This finds 64 different 5 x 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # First fully connected layer\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "\n",
    "    # Second fully connected layer\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "    # d4 contains unscaled values\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "\n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
